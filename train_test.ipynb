{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "969362fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchsummary\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from model import LeNet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73de0f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1295aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             156\n",
      "          Layer_C1-2            [-1, 6, 28, 28]               0\n",
      "              Tanh-3            [-1, 6, 28, 28]               0\n",
      "          Layer_S2-4            [-1, 6, 14, 14]              12\n",
      "              Tanh-5            [-1, 6, 14, 14]               0\n",
      "          Layer_C3-6           [-1, 16, 10, 10]           1,516\n",
      "              Tanh-7           [-1, 16, 10, 10]               0\n",
      "          Layer_S4-8             [-1, 16, 5, 5]              32\n",
      "              Tanh-9             [-1, 16, 5, 5]               0\n",
      "           Conv2d-10            [-1, 120, 1, 1]          48,120\n",
      "         Layer_C5-11            [-1, 120, 1, 1]               0\n",
      "             Tanh-12            [-1, 120, 1, 1]               0\n",
      "           Linear-13                   [-1, 84]          10,164\n",
      "             Tanh-14                   [-1, 84]               0\n",
      "              RBF-15                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 60,000\n",
      "Trainable params: 60,000\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.16\n",
      "Params size (MB): 0.23\n",
      "Estimated Total Size (MB): 0.39\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check model structure\n",
    "summary(model,(1,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2710ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b06735ddf0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# kernel example 0\n",
    "file = './RBF_kernel/0_RBF.jpg'\n",
    "image = cv2.imread(file, 0)\n",
    "image = cv2.threshold(image,127,1,cv2.THRESH_BINARY)[1]*-1+1\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26bbd3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.05,), (0.5,))\n",
    "    ])\n",
    "\n",
    "train_data = datasets.MNIST(root='data/', train=True, transform=transform, download=True)\n",
    "test_data = datasets.MNIST(root='data/', train=False, transform=transform, download=True)\n",
    "\n",
    "# data loader\n",
    "train_loader = DataLoader(dataset = train_data, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(dataset = test_data, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c94765dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch=100, w_decay=0):\n",
    "    # optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=w_decay)\n",
    "    \n",
    "    # loss function\n",
    "    def loss_fn(output, target):\n",
    "        loss = output[target==1].pow(2).sum()\n",
    "        loss += torch.log(np.exp(-0.1)+torch.exp(-output[target==0]).sum())\n",
    "        return loss\n",
    "\n",
    "    # training\n",
    "    train_loss_list=[]\n",
    "    train_accuracy_list=[]\n",
    "    for i in range(epoch):\n",
    "        train_loss = 0\n",
    "        train_accuracy = 0\n",
    "        #load data\n",
    "        for data, target in train_loader:\n",
    "            data = torch.Tensor(np.pad(data,((0,0),(0,0),(2,2),(2,2)),'constant', constant_values=-0.1))\n",
    "            target = nn.functional.one_hot(target).float()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #forward propagation\n",
    "            y_pred = model(data)\n",
    "            loss = loss_fn(y_pred,target)\n",
    "            \n",
    "           #backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_accuracy += (torch.argmin(model(data),dim=1)==torch.argmax(target,dim=1)).sum().item()\n",
    "\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_loss *= 256\n",
    "        train_loss_list.append(train_loss)\n",
    "\n",
    "        train_accuracy /= len(train_loader.dataset)\n",
    "        train_accuracy_list.append(train_accuracy)\n",
    "\n",
    "\n",
    "        if i%1==0:\n",
    "            print('epoch : {}/{}, train_loss : {:.8f}, train_acc : {:.2f}'.format(i+1,epoch,train_loss,train_accuracy))\n",
    "    return(train_loss_list,train_accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed94c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    accuracy = 0\n",
    "    for data, target in test_loader:\n",
    "        data = torch.Tensor(np.pad(data,((0,0),(0,0),(2,2),(2,2)),'constant', constant_values=-0.1))\n",
    "        y_pred = model(data)\n",
    "        accuracy += (torch.argmin(y_pred,dim=1)==target).sum().item()\n",
    "    accuracy /= len(test_loader.dataset)\n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39ed4cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/20, train_loss : 8779.72153802, train_acc : 0.78\n",
      "epoch : 2/20, train_loss : 2820.84180911, train_acc : 0.95\n",
      "epoch : 3/20, train_loss : 1950.66173802, train_acc : 0.96\n",
      "epoch : 4/20, train_loss : 1619.30782695, train_acc : 0.97\n",
      "epoch : 5/20, train_loss : 1325.58238203, train_acc : 0.97\n",
      "epoch : 6/20, train_loss : 1087.58044173, train_acc : 0.98\n",
      "epoch : 7/20, train_loss : 925.66773652, train_acc : 0.98\n",
      "epoch : 8/20, train_loss : 818.87937266, train_acc : 0.98\n",
      "epoch : 9/20, train_loss : 741.80583577, train_acc : 0.98\n",
      "epoch : 10/20, train_loss : 684.43905036, train_acc : 0.99\n",
      "epoch : 11/20, train_loss : 631.57666410, train_acc : 0.99\n",
      "epoch : 12/20, train_loss : 581.03060609, train_acc : 0.99\n",
      "epoch : 13/20, train_loss : 548.16703737, train_acc : 0.99\n",
      "epoch : 14/20, train_loss : 525.24357308, train_acc : 0.99\n",
      "epoch : 15/20, train_loss : 500.21201673, train_acc : 0.99\n",
      "epoch : 16/20, train_loss : 480.70574997, train_acc : 0.99\n",
      "epoch : 17/20, train_loss : 456.13778669, train_acc : 0.99\n",
      "epoch : 18/20, train_loss : 432.97099652, train_acc : 0.99\n",
      "epoch : 19/20, train_loss : 418.94579390, train_acc : 0.99\n",
      "epoch : 20/20, train_loss : 403.35378678, train_acc : 0.99\n"
     ]
    }
   ],
   "source": [
    "train_hist_loss, train_hist_acc = train(model,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d08b138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9872"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model,'LeNet_1998.pt')\n",
    "test(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
